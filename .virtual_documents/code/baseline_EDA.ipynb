


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error


cdf = pd.read_csv('cleaned_ameshousing.csv')


pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)


cdf.head()





plt.figure(figsize=(6, 25))
sns.heatmap(cdf.corr()[['SalePrice']].sort_values(by = 'SalePrice', ascending = False), 
           vmin= -1, 
           vmax= 1, 
           annot = True, 
           cmap = 'coolwarm')


sub = cdf[['SalePrice','Overall Qual','Exter Qual','Gr Liv Area','Kitchen Qual','Garage Cars','Garage Area','Total Bsmt SF']]


sub.to_csv('baseline_ameshousing.csv', index = False)





df = pd.read_csv('baseline_ameshousing.csv')


df.head()


df.shape


cdf['Overall Qual'].value_counts()


df['Overall Qual'].value_counts()





plt.figure(figsize=(6, 8))
sns.heatmap(df.corr()[['SalePrice']].sort_values(by = 'SalePrice', ascending = False), 
           vmin= -1, 
           vmax= 1, 
           annot = True, 
           cmap = 'coolwarm')


sns.pairplot(df, corner = True, 
            x_vars= 'SalePrice')


fig, ax = plt.subplots(figsize = (7, 5))
sns.barplot(df, x = 'Exter Qual', y = 'SalePrice', estimator='median', errorbar =('pi', 50))
ax.bar_label(ax.containers[0], label_type='center')


fig, ax = plt.subplots(figsize = (7, 5))
sns.barplot(df, x = 'Garage Cars', y = 'SalePrice', estimator='median', errorbar =('pi', 50))
ax.bar_label(ax.containers[0], label_type='center')


fig, ax = plt.subplots(figsize = (7, 5))
sns.barplot(df, x = 'Kitchen Qual', y = 'SalePrice', estimator='median', errorbar =('pi', 50))
ax.bar_label(ax.containers[0], label_type='center')


fig, ax = plt.subplots(figsize = (7, 5))
sns.barplot(cdf, x= 'Overall Qual', y='SalePrice', estimator='median', errorbar =('pi', 50))
ax.bar_label(ax.containers[0], label_type='center')














X = df.drop(columns = 'SalePrice')

y = df['SalePrice']


scores = []

for i in range(20, 31):
    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = i/100)
    lr = LinearRegression()
    lr.fit(X_train, y_train)
    lr.predict(X_test)
    train_score = lr.score(X_train, y_train)
    test_score = lr.score(X_test, y_test)
    scores.append({'i' : i, 'train_score' : train_score, 'test_score' : test_score})
lr_scores = pd.DataFrame(scores)


lr_scores
# 0.26 test size


scores = []

for i in range(20, 31):
    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = i/100)
    rfr = RandomForestRegressor()
    rfr.fit(X_train, y_train)
    rfr.predict(X_test)
    train_score = rfr.score(X_train, y_train)
    test_score = rfr.score(X_test, y_test)
    scores.append({'i' : i, 'train_score' : train_score, 'test_score' : test_score})
rfr_scores = pd.DataFrame(scores)


rfr_scores
# test size 23


scores = []

for i in range(20, 31):
    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = i/100)
    dtr = DecisionTreeRegressor()
    dtr.fit(X_train, y_train)
    dtr.predict(X_test)
    train_score = dtr.score(X_train, y_train)
    test_score = dtr.score(X_test, y_test)
    scores.append({'i' : i, 'train_score' : train_score, 'test_score' : test_score})
dtr_scores = pd.DataFrame(scores)


dtr_scores
# test size 28


scores = []

for i in range(20, 31):
    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = i/100)
    knn = KNeighborsRegressor()
    knn.fit(X_train, y_train)
    knn.predict(X_test)
    train_score = knn.score(X_train, y_train)
    test_score = knn.score(X_test, y_test)
    scores.append({'i' : i, 'train_score' : train_score, 'test_score' : test_score})
knn_scores = pd.DataFrame(scores)


knn_scores
# test size 24








from sklearn.metrics import mean_absolute_percentage_error


X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.26)

lr = LinearRegression()

lr.fit(X_train, y_train)


lr_preds = lr.predict(X_test)
baseline_preds = np.full_like(y_test, y_test.mean())


lr.score(X_test, y_test)
# 0.800931


lr_model_rmse = np.sqrt(mean_squared_error(y_test, lr_preds))
print(lr_model_rmse)


baseline_rmse = np.sqrt(mean_squared_error(y_test, baseline_preds))
print(baseline_rmse)





mean_absolute_percentage_error(y_test, lr_preds)


mean_absolute_percentage_error(y_test, baseline_preds)





X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.23)

rfr = RandomForestRegressor()

rfr.fit(X_train, y_train)


rfr_preds = rfr.predict(X_test)
baseline_preds = np.full_like(y_test, y_test.mean())


rfr.score(X_test, y_test)
# 0.855978


np.sqrt(mean_squared_error(y_test, rfr_preds))


np.sqrt(mean_squared_error(y_test, baseline_preds))


mean_absolute_percentage_error(y_test, rfr_preds)


mean_absolute_percentage_error(y_test, baseline_preds)





X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.28)

dtr = DecisionTreeRegressor()

dtr.fit(X_train, y_train)


dtr_preds = dtr.predict(X_test)
baseline_preds = np.full_like(y_test, y_test.mean())


dtr.score(X_test, y_test)
# 0.800105


np.sqrt(mean_squared_error(y_test, dtr_preds))


np.sqrt(mean_squared_error(y_test, baseline_preds))





X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.24)

knn = KNeighborsRegressor()

knn.fit(X_train, y_train)


knn_preds = knn.predict(X_test)
baseline_preds = np.full_like(y_test, y_test.mean())


knn.score(X_test, y_test)
# 0.790094


np.sqrt(mean_squared_error(y_test, knn_preds))


np.sqrt(mean_squared_error(y_test, baseline_preds))






